{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title\n",
    "Author: Tom Chapman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding\n",
    "Since their inception, online marketplaces have fundamentally shifted how consumers shop. With a near limitless number of products and services available online, it has never been less important for a consumer to walk into a brick-and-mortar store to make a purchase. However, identifying which products or services are high-quality has become increasingly difficult. The popularity of the 5-star rating scale has led to a number of well-documented challenges. [Harvard Business Review](https://hbr.org/2019/07/the-problems-with-5-star-rating-systems-and-how-to-fix-them) summed these challenges up nicely as follows:\n",
    "\n",
    "- There is little incentive for consumers to provide truthful feedback, meaning that extreme experiences (whether positive or negative) are much more likely to lead a consumer to leave a review.\n",
    "- Compounding the lack of incentive for truth, 5-star ratings are prone to grade inflation. There is no correlation between the star-rating and the sentiment the user expresses in a review. It's possible (and surprisingly common) for a user to hate a product, excorriate it in a review, and then rate it 5-stars. This leads to inflated ratings, and makes it harder for the consumer to understand the review variance between products.\n",
    "\n",
    "My tool is intended to help address rating inflation by classifying user feedback as positive or negative based on its content. I also prioritized ease-of-implementation by limiting model size and complexity wherever possible. I want this tool to be accessible to sellers without significant compute resources, so it needs to function well on a large dataset AND be runnable on a single machine. I used natural language processing for this project, AND IMPLEMENTED A TOOL CAPABLE OF INGESTING USER REVIEWS FROM XXXX \n",
    "\n",
    "Amazon is the largest online marketplace currently in existence, and its challenges with rating inflation are well-documented. My tool could be useful to help reclassify ratings based on their sentiment for Amazon itself. It is also useful for sellers that want to move away from Amazon or implement their own storefront. By implementing my algorithm in a newly-created storefront, sellers can better classify consumer feedback and derive a more accurate understanding of how their products or services are being received.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import plot_confusion_matrix, confusion_matrix, make_scorer, recall_score, accuracy_score, precision_score, f1_score, classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid, GridSearchCV, cross_validate, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from imblearn.pipeline import Pipeline as ImPipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "I utilized a number of sklearn's modeling techniques for the project, and performed grid searches to optimize the hyperparameters of the best-performing model. As noted in the data-preparation description, I experimented with the inclusion of bi-grams and tri-grams created from user input during the modeling process as well. Ultimately..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "df = pd.read_csv('../data/train_cleaned_10sw.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>toks</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>This sound track was beautiful! It paints the ...</td>\n",
       "      <td>sound track beautiful paint senery mind well w...</td>\n",
       "      <td>['sound', 'track', 'beautiful', 'paint', 'sene...</td>\n",
       "      <td>[('sound', 'track'), ('track', 'beautiful'), (...</td>\n",
       "      <td>[('sound', 'track', 'beautiful'), ('track', 'b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>I'm reading a lot of reviews saying that this ...</td>\n",
       "      <td>i'm reading lot review say best game soundtrac...</td>\n",
       "      <td>[\"i'm\", 'reading', 'lot', 'review', 'say', 'be...</td>\n",
       "      <td>[(\"i'm\", 'reading'), ('reading', 'lot'), ('lot...</td>\n",
       "      <td>[(\"i'm\", 'reading', 'lot'), ('reading', 'lot',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>This soundtrack is my favorite music of all ti...</td>\n",
       "      <td>soundtrack favorite music time hand intense sa...</td>\n",
       "      <td>['soundtrack', 'favorite', 'music', 'time', 'h...</td>\n",
       "      <td>[('soundtrack', 'favorite'), ('favorite', 'mus...</td>\n",
       "      <td>[('soundtrack', 'favorite', 'music'), ('favori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>I truly like this soundtrack and I enjoy video...</td>\n",
       "      <td>truly soundtrack enjoy video game music play g...</td>\n",
       "      <td>['truly', 'soundtrack', 'enjoy', 'video', 'gam...</td>\n",
       "      <td>[('truly', 'soundtrack'), ('soundtrack', 'enjo...</td>\n",
       "      <td>[('truly', 'soundtrack', 'enjoy'), ('soundtrac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>If you've played the game, you know how divine...</td>\n",
       "      <td>played game know divine music every single son...</td>\n",
       "      <td>['played', 'game', 'know', 'divine', 'music', ...</td>\n",
       "      <td>[('played', 'game'), ('game', 'know'), ('know'...</td>\n",
       "      <td>[('played', 'game', 'know'), ('game', 'know', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text  \\\n",
       "0          2  This sound track was beautiful! It paints the ...   \n",
       "1          2  I'm reading a lot of reviews saying that this ...   \n",
       "2          2  This soundtrack is my favorite music of all ti...   \n",
       "3          2  I truly like this soundtrack and I enjoy video...   \n",
       "4          2  If you've played the game, you know how divine...   \n",
       "\n",
       "                                        text_cleaned  \\\n",
       "0  sound track beautiful paint senery mind well w...   \n",
       "1  i'm reading lot review say best game soundtrac...   \n",
       "2  soundtrack favorite music time hand intense sa...   \n",
       "3  truly soundtrack enjoy video game music play g...   \n",
       "4  played game know divine music every single son...   \n",
       "\n",
       "                                                toks  \\\n",
       "0  ['sound', 'track', 'beautiful', 'paint', 'sene...   \n",
       "1  [\"i'm\", 'reading', 'lot', 'review', 'say', 'be...   \n",
       "2  ['soundtrack', 'favorite', 'music', 'time', 'h...   \n",
       "3  ['truly', 'soundtrack', 'enjoy', 'video', 'gam...   \n",
       "4  ['played', 'game', 'know', 'divine', 'music', ...   \n",
       "\n",
       "                                             bigrams  \\\n",
       "0  [('sound', 'track'), ('track', 'beautiful'), (...   \n",
       "1  [(\"i'm\", 'reading'), ('reading', 'lot'), ('lot...   \n",
       "2  [('soundtrack', 'favorite'), ('favorite', 'mus...   \n",
       "3  [('truly', 'soundtrack'), ('soundtrack', 'enjo...   \n",
       "4  [('played', 'game'), ('game', 'know'), ('know'...   \n",
       "\n",
       "                                            trigrams  \n",
       "0  [('sound', 'track', 'beautiful'), ('track', 'b...  \n",
       "1  [(\"i'm\", 'reading', 'lot'), ('reading', 'lot',...  \n",
       "2  [('soundtrack', 'favorite', 'music'), ('favori...  \n",
       "3  [('truly', 'soundtrack', 'enjoy'), ('soundtrac...  \n",
       "4  [('played', 'game', 'know'), ('game', 'know', ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3600000 entries, 0 to 3599999\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Dtype \n",
      "---  ------        ----- \n",
      " 0   sentiment     int64 \n",
      " 1   text          object\n",
      " 2   text_cleaned  object\n",
      " 3   toks          object\n",
      " 4   bigrams       object\n",
      " 5   trigrams      object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 192.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1799993\n",
       "2    1799984\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment        0\n",
      "text             0\n",
      "text_cleaned    23\n",
      "toks             0\n",
      "bigrams          0\n",
      "trigrams         0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>toks</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>217919</th>\n",
       "      <td>2</td>\n",
       "      <td>ò ñàìà ì áèìà ñí è íí ñàìé áèìé äèñ . ß ìíäó ñ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294435</th>\n",
       "      <td>2</td>\n",
       "      <td>............ ..... ..... ...... ...... ..........</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556297</th>\n",
       "      <td>2</td>\n",
       "      <td>it's very good ... .... ... ... ... ... ... .....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629878</th>\n",
       "      <td>1</td>\n",
       "      <td>...............................</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680354</th>\n",
       "      <td>2</td>\n",
       "      <td>ò äèí è ñàì ìè áèì ìèò. à ò ññèè èàò ìà èäàò ä...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440939</th>\n",
       "      <td>1</td>\n",
       "      <td>|||||||||||||||||||| |||||||||| ||||||||||||||...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786231</th>\n",
       "      <td>2</td>\n",
       "      <td>38493 34740 47383 37054 48624 78568? 18581 286...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989004</th>\n",
       "      <td>2</td>\n",
       "      <td>&amp;#4315;&amp;#4304;&amp;#4306;&amp;#4304;&amp;#4320;&amp;#4312;&amp;#43...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005370</th>\n",
       "      <td>1</td>\n",
       "      <td>&amp;#1575;&amp;#1606;&amp;#1578;&amp;#1605; &amp;#1594;&amp;#1610;&amp;#1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071299</th>\n",
       "      <td>2</td>\n",
       "      <td>&amp;#1042;&amp;#1089;&amp;#1077; &amp;#1087;&amp;#1088;&amp;#1080;&amp;#1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220519</th>\n",
       "      <td>2</td>\n",
       "      <td>!!!!! ! 1 !!!!!!!!!! 234 !!!!!!!! 2 !! 34 !!!!...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2282778</th>\n",
       "      <td>2</td>\n",
       "      <td>'''' ''' '''''' '''''' '''''' ''''' '''' '''''...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2330988</th>\n",
       "      <td>1</td>\n",
       "      <td>&amp;#12479;&amp;#12483;&amp;#12503; &amp;#12398; &amp;#20869;&amp;#20...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2357286</th>\n",
       "      <td>2</td>\n",
       "      <td>&amp;#1579;&amp;#1604;&amp;#1575;&amp;#1579;&amp;#1577; &amp;#1602;&amp;#1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375843</th>\n",
       "      <td>2</td>\n",
       "      <td>&amp;#47784;&amp;#46160; &amp;#45208;&amp;#47924;&amp;#47196; &amp;#46...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2490037</th>\n",
       "      <td>1</td>\n",
       "      <td>&amp;#51060;&amp;#44148; &amp;#53944;&amp;#47000;&amp;#53433;&amp;#453...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2604873</th>\n",
       "      <td>1</td>\n",
       "      <td>........ ...... .. . .... ... ...... ..... ......</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2618232</th>\n",
       "      <td>2</td>\n",
       "      <td>'''''''''' ''''', ''''' ''''''''''', '''''''''...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2751281</th>\n",
       "      <td>2</td>\n",
       "      <td>À ÀÌ ÖÈÄÀ À ÖíÀ óÀ ÖíÀ ¡ 3¿¡ 5ÀÌ Ü¿ì Ñ''Ù ¿¡' ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798192</th>\n",
       "      <td>2</td>\n",
       "      <td>Very Good!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3392964</th>\n",
       "      <td>2</td>\n",
       "      <td>Good</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3545242</th>\n",
       "      <td>2</td>\n",
       "      <td>Good book. This is a very very very very very ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3584048</th>\n",
       "      <td>1</td>\n",
       "      <td>' ' '''' '''' '' '' ''' '''''? '' '' ' '' ''' ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment                                               text  \\\n",
       "217919           2  ò ñàìà ì áèìà ñí è íí ñàìé áèìé äèñ . ß ìíäó ñ...   \n",
       "294435           2  ............ ..... ..... ...... ...... ..........   \n",
       "556297           2  it's very good ... .... ... ... ... ... ... .....   \n",
       "629878           1                    ...............................   \n",
       "680354           2  ò äèí è ñàì ìè áèì ìèò. à ò ññèè èàò ìà èäàò ä...   \n",
       "1440939          1  |||||||||||||||||||| |||||||||| ||||||||||||||...   \n",
       "1786231          2  38493 34740 47383 37054 48624 78568? 18581 286...   \n",
       "1989004          2  &#4315;&#4304;&#4306;&#4304;&#4320;&#4312;&#43...   \n",
       "2005370          1  &#1575;&#1606;&#1578;&#1605; &#1594;&#1610;&#1...   \n",
       "2071299          2  &#1042;&#1089;&#1077; &#1087;&#1088;&#1080;&#1...   \n",
       "2220519          2  !!!!! ! 1 !!!!!!!!!! 234 !!!!!!!! 2 !! 34 !!!!...   \n",
       "2282778          2  '''' ''' '''''' '''''' '''''' ''''' '''' '''''...   \n",
       "2330988          1  &#12479;&#12483;&#12503; &#12398; &#20869;&#20...   \n",
       "2357286          2  &#1579;&#1604;&#1575;&#1579;&#1577; &#1602;&#1...   \n",
       "2375843          2  &#47784;&#46160; &#45208;&#47924;&#47196; &#46...   \n",
       "2490037          1  &#51060;&#44148; &#53944;&#47000;&#53433;&#453...   \n",
       "2604873          1  ........ ...... .. . .... ... ...... ..... ......   \n",
       "2618232          2  '''''''''' ''''', ''''' ''''''''''', '''''''''...   \n",
       "2751281          2  À ÀÌ ÖÈÄÀ À ÖíÀ óÀ ÖíÀ ¡ 3¿¡ 5ÀÌ Ü¿ì Ñ''Ù ¿¡' ...   \n",
       "2798192          2                                         Very Good!   \n",
       "3392964          2                                               Good   \n",
       "3545242          2  Good book. This is a very very very very very ...   \n",
       "3584048          1  ' ' '''' '''' '' '' ''' '''''? '' '' ' '' ''' ...   \n",
       "\n",
       "        text_cleaned toks bigrams trigrams  \n",
       "217919           NaN   []      []       []  \n",
       "294435           NaN   []      []       []  \n",
       "556297           NaN   []      []       []  \n",
       "629878           NaN   []      []       []  \n",
       "680354           NaN   []      []       []  \n",
       "1440939          NaN   []      []       []  \n",
       "1786231          NaN   []      []       []  \n",
       "1989004          NaN   []      []       []  \n",
       "2005370          NaN   []      []       []  \n",
       "2071299          NaN   []      []       []  \n",
       "2220519          NaN   []      []       []  \n",
       "2282778          NaN   []      []       []  \n",
       "2330988          NaN   []      []       []  \n",
       "2357286          NaN   []      []       []  \n",
       "2375843          NaN   []      []       []  \n",
       "2490037          NaN   []      []       []  \n",
       "2604873          NaN   []      []       []  \n",
       "2618232          NaN   []      []       []  \n",
       "2751281          NaN   []      []       []  \n",
       "2798192          NaN   []      []       []  \n",
       "3392964          NaN   []      []       []  \n",
       "3545242          NaN   []      []       []  \n",
       "3584048          NaN   []      []       []  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.isna().sum())\n",
    "df[df['text_cleaned'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing text_cleaned values\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save off feature combinations for use in model iteration\n",
    "X = df['text_cleaned']\n",
    "\n",
    "X_bigrams = df[['text_cleaned', 'bigrams']]\n",
    "X_trigrams = df[['text_cleaned', 'trigrams']]\n",
    "X_allgrams = df[['text_cleaned', 'bigrams', 'trigrams']]\n",
    "\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Classifier\n",
    "To begin modelling efforts, I built a dummy classifier that simply guesses the most common class every time. Given that our training data is almost (but not perfectly) balanced, we should expect it to predict that every review is negative since there are slightly more negative reviews than positive reviews. If we can't beat a 50-50 guess with a dataset this large, something is horribly wrong. Predictably, the dummy classifier achieved an accuracy score of almost exactly 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Dummy Classifier pipeline\n",
    "dummy_pipe = ImPipeline(steps=[\n",
    "                                ('vect', TfidfVectorizer(max_features=max_features)),\n",
    "                                ('dc', DummyClassifier(strategy='most_frequent',\n",
    "                                                           random_state=42))\n",
    "                              ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5000012500079861\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit dummy pipe on the training data and plot confusion matrix\n",
    "dummy_pipe.fit(X, y)\n",
    "dummy_yhat = dummy_pipe.predict(X)\n",
    "plot_confusion_matrix(dummy_pipe, X, y, normalize='true');\n",
    "print(accuracy_score(y, dummy_yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes\n",
    "MNB is a commonly-used algorithm for natural language processing due to effectiveness in classifying topics while maintaining a low training time and relative simplicity. It predicts the probability that a given document belongs to a particular class based on the words it contains. I employed a multinomial naive bayes classifier as my first simple model for these reasons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8284569595861306\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instantiate the Multinomial Naieve Bayes Pipeline\n",
    "mnb_pipe = ImPipeline(steps=[\n",
    "                            ('vect', TfidfVectorizer(max_features=max_features)),\n",
    "                            ('mnb', MultinomialNB())\n",
    "                            ]\n",
    ")\n",
    "\n",
    "# Fit MNB pipe on the training data, get predictions and plot confusion matrix\n",
    "mnb_pipe.fit(X_bigrams, y)\n",
    "mnb_yhat = mnb_pipe.predict(X_bigrams)\n",
    "plot_confusion_matrix(mnb_pipe, X, y, normalize='true');\n",
    "print(accuracy_score(y, mnb_yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "821050"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_pipe.named_steps['mnb'].n_features_\n",
    "#__mnb.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([63.91176295, 64.27754903, 63.07658076, 62.96271181, 63.14784789]),\n",
       " 'score_time': array([14.80177712, 14.56706309, 14.5999763 , 14.49988723, 14.33135796]),\n",
       " 'test_score': array([0.81850038, 0.81476842, 0.81272648, 0.81008618, 0.81112924])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtained cross-validated accuracy score\n",
    "cross_validate(mnb_pipe, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 'fit_time': 63.91176295, 64.27754903, 63.07658076, 62.96271181, 63.14784789\n",
    "- 'score_time': 14.80177712, 14.56706309, 14.5999763 , 14.49988723, 14.33135796\n",
    "- 'test_score': 0.81850038, 0.81476842, 0.81272648, 0.81008618, 0.81112924"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using N-grams as Features\n",
    "To see if I could improve on the model's performance over using single words, I tried giving it bi-grams and tri-grams as additional features. Ultimately XXXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Multinomial Naieve Bayes Pipeline\n",
    "mnb_bigrams_pipe = ImPipeline(steps=[\n",
    "                                    ('vect', TfidfVectorizer(max_features=max_features)),\n",
    "                                    ('mnb', MultinomialNB())\n",
    "                                    ]\n",
    ")\n",
    "\n",
    "# Fit MNB pipe on the training data, get predictions and plot confusion matrix\n",
    "mnb_pipe.fit(X_grams, y)\n",
    "mnb_yhat = mnb_pipe.predict(X_grams)\n",
    "plot_confusion_matrix(mnb_pipe, X_grams, y, normalize='true');\n",
    "print(accuracy_score(y, mnb_yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent Classifier\n",
    "Stochastic gradient descent is another technique that is very common in natural language processing due to its efficiency. Rather than calculating the gradient at each iteration using every observation, it selects one observation at random for each step, drastically reducing the computational requirements. It also works very well with sparse data, which makes it a natural fit for NLP. Given the size of my dataset, SGD was a natural next step and XXXX..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the SGDC Classifier pipeline\n",
    "sgdc_pipe = ImPipeline(steps=[\n",
    "                            ('vect', TfidfVectorizer(max_features=max_features,\n",
    "                                                    #max_df=0.95,\n",
    "                                                   # min_df=0.05\n",
    "                                                    )),\n",
    "                            ('sgdc', SGDClassifier(random_state=42))\n",
    "                            ]\n",
    ")\n",
    "\n",
    "#Fit SGDC pipe on the training data, get predictions and plot confusion matrix\n",
    "sgdc_pipe.fit(X, y)\n",
    "sgdc_yhat = sgdc_pipe.predict(X)\n",
    "plot_confusion_matrix(sgdc_pipe, X, y, normalize='true');\n",
    "print(accuracy_score(y, sgdc_yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtained cross-validated accuracy score\n",
    "# cross_validate(sgdc_pipe, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgdc_params = {\n",
    "            'sgdc__alpha': [1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3, 0.0002, 0.0005],\n",
    "            #'sgdc__n_iter': [50, 100, 500],\n",
    "            'sgdc__loss': ['hinge', 'log', 'huber'],\n",
    "            'sgdc__penalty': ['l2', 'l1', 'elasticnet'],\n",
    "            'vect__max_features': [None, 50000, 100000, 200000]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sgdc_gs = GridSearchCV(sgdc_pipe, param_grid=sgdc_params, n_jobs=-2, verbose=3, cv=3)\n",
    "#sgdc_gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgdc_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the SDGC Classifier pipeline\n",
    "sgdc_tuned_pipe = ImPipeline(steps=[\n",
    "                            ('vect', TfidfVectorizer(max_features=50000,\n",
    "                                                    #max_df=0.95,\n",
    "                                                   # min_df=0.05\n",
    "                                                    )),\n",
    "                            ('sgdc', SGDClassifier(random_state=42,\n",
    "                                                  alpha=0.0001,\n",
    "                                                  loss = 'hinge',\n",
    "                                                  penalty='l2'\n",
    "                                                  ))\n",
    "                            ]\n",
    ")\n",
    "\n",
    "#Fit SGDC pipe on the training data, get predictions and plot confusion matrix\n",
    "sgdc_tuned_pipe.fit(X, y)\n",
    "sgdc_tuned_yhat = sgdc_tuned_pipe.predict(X)\n",
    "plot_confusion_matrix(sgdc_tuned_pipe, X, y, normalize='true');\n",
    "print(accuracy_score(y, sgdc_tuned_yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtained cross-validated accuracy score\n",
    "cross_validate(sgdc_pipe, X_grams, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('sgdc_pkl', 'wb') as files:\n",
    "    pickle.dump(sgdc_tuned_pipe, files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using N-grams as Features \n",
    "To see if I could improve on the model's performance over using single words, I tried giving it bi-grams and tri-grams as additional features. Ultimately XXXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the SGDC Classifier pipeline\n",
    "sgdc_ngrams_pipe = ImPipeline(steps=[\n",
    "                            ('vect', TfidfVectorizer(max_features=max_features,\n",
    "                                                    #max_df=0.95,\n",
    "                                                   # min_df=0.05\n",
    "                                                    )),\n",
    "                            ('sgdc', SGDClassifier(random_state=42))\n",
    "                            ]\n",
    ")\n",
    "\n",
    "#Fit SGDC pipe on the training data, get predictions and plot confusion matrix\n",
    "sgdc_ngrams_pipe.fit(X_grams, y)\n",
    "sgdc_ngrams_yhat = sgdc_ngrams_pipe.predict(X_grams)\n",
    "plot_confusion_matrix(sgdc_ngrams_pipe, X_grams, y, normalize='true');\n",
    "print(accuracy_score(y, sgdc_ngrams_yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtained cross-validated accuracy score\n",
    "cross_validate(sgdc_pipe, X_grams, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Random Forest Pipeline\n",
    "rf_pipe = ImPipeline(steps=[\n",
    "                            ('vect', TfidfVectorizer(max_features=max_features)),\n",
    "                            ('rf', RandomForestClassifier())\n",
    "                            ]\n",
    ")\n",
    "\n",
    "# Fit RF pipe on the training data, get predictions and plot confusion matrix\n",
    "# rf_pipe.fit(X, y)\n",
    "rf_yhat = rf_pipe.predict(X)\n",
    "plot_confusion_matrix(rf_pipe, X, y);\n",
    "print(accuracy_score(y, rf_yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtained cross-validated accuracy score\n",
    "# cross_validate(rf_pipe, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('rf_pkl', 'wb') as files:\n",
    "    pickle.dump(rf_pipe, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the gradient boosting classifier pipeline\n",
    "gbc_pipe = ImPipeline(steps=[\n",
    "                                 ('vect', TfidfVectorizer(max_features=max_features)),\n",
    "                                 ('gbc',  GradientBoostingClassifier())\n",
    "                                ]\n",
    ")\n",
    "\n",
    "#Fit SGDC pipe on the training data, get predictions and plot confusion matrix\n",
    "gbc_pipe.fit(X, y)\n",
    "gbc_yhat = gbc_pipe.predict(X)\n",
    "plot_confusion_matrix(gbc_pipe, X, y);\n",
    "print(accuracy_score(y, gbc_yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtained cross-validated accuracy score\n",
    "cross_validate(gbc_pipe, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the gradient boosting classifier pipeline\n",
    "gbc_ngrams_pipe = ImPipeline(steps=[\n",
    "                                 ('vect', TfidfVectorizer(max_features=max_features)),\n",
    "                                 ('gbc',  GradientBoostingClassifier())\n",
    "                                ]\n",
    ")\n",
    "\n",
    "#Fit SGDC pipe on the training data, get predictions and plot confusion matrix\n",
    "gbc_ngrams_pipe.fit(X_grams, y)\n",
    "gbc_ngrams_yhat = gbc_ngrams_pipe.predict(X_grams)\n",
    "plot_confusion_matrix(gbc_ngrams_pipe, X_grams, y);\n",
    "print(accuracy_score(y, gbc_yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtained cross-validated accuracy score\n",
    "cross_validate(gbc_pipe, X_grams, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model Evaluation\n",
    "The XXXX model ended up performing best on the test data, so I selected it as the appropriate model to deploy. \n",
    "\n",
    "- Score\n",
    "- what did it do well\n",
    "- what are its shortcomings\n",
    "- how well does it solve the business problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spark-cap-env)",
   "language": "python",
   "name": "spark-cap-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
