{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/banner.jpeg)\n",
    "Photo by <a href=\"https://unsplash.com/@towfiqu999999?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\">Towfiqu barbhuiya</a> on <a href=\"https://unsplash.com/s/photos/customer-ratings?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\">Unsplash</a>\n",
    "  \n",
    "# I HATE this Product! Five Stars!\n",
    "### Reducing Rating Inflation Using NLP\n",
    "Author: Tom Chapman | [email](mailto:thomas.h.chapman@gmail.com) | [linkedin](https://www.linkedin.com/in/thomashchapman/) | [github](https://github.com/ThomasHChapman)\n",
    "\n",
    "Most online marketplaces use 5-star product rating systems which are prone to rating inflation, obscuring product quality and customer sentiment. In addition to being problematic for the consumer, rating inflation makes it difficult for sellers to parse customer feedback and understand how their products are being received by the public. My project uses natural language processing to train a model on review sentiment so that it can be used to accurately classify customer reviews based on their content.\n",
    "\n",
    "\n",
    "## Business Understanding\n",
    "Since their inception, online marketplaces have fundamentally shifted how consumers shop. With a near limitless number of products and services available online, it has never been easier to avoid the hassle of brick-and-mortar stores. However, identifying which products or services are high-quality has become increasingly difficult. The popularity of the 5-star rating scale has led to a number of well-documented challenges. [Harvard Business Review](https://hbr.org/2019/07/the-problems-with-5-star-rating-systems-and-how-to-fix-them) summed these challenges up nicely as follows:\n",
    "\n",
    "- There is little incentive for consumers to provide truthful feedback, meaning that extreme experiences (whether positive or negative) are much more likely to lead a consumer to leave a review.\n",
    "- Compounding the lack of incentive for truth, 5-star rating scales are prone to grade inflation. There is no correlation between the star-rating and the sentiment the user expresses in a review. It's possible (and surprisingly common) for a user to hate a product, excoriate it in a review, and then rate it 5-stars. This leads to inflated ratings, and makes it harder for the consumer to understand the meaning behind varied product ratings. How much better is a product with a 4.7 star rating than a 4.5 star average rating?\n",
    "My model is intended to help address rating inflation by classifying user feedback as positive or negative based on its content.\n",
    "\n",
    "Amazon is the largest online marketplace currently in existence, and its challenges with rating inflation are [common knowledge](https://www.nytimes.com/2021/06/18/technology/amazon-reviews.html). However, any marketplace that uses a five-star rating system (Google Play, Apple App Store, Chewy, Wal-mart, Etsy, Rakuten, etc.) can utilize my model to reclassify user reviews into positive or negative polarity. Offering customers a clearer display of product quality allows customers to make more informed purchases, and should drive improved satisfaction. It should also help mitigate poor quality or scam sellers inherently, as poor reviews are less likely to be drowned out by inflated ratings.\n",
    "\n",
    "The tool is also useful for sellers that want to move away from Amazon or implement their own storefront. By implementing my algorithm in a newly-created storefront, sellers can mostly automate the classification of consumer feedback and derive a more accurate understanding of how their products or services are being received. On average, Amazon sellers pay the website about 15% of their sale price on each item sold. There's no question the visibility and customer reach that Amazon provides is valuable, but 15% is an extremely hefty cost for small companies. For certain product categories, the cost per item can range as high as 45%, an enormous amount to pay simply for the storefront component of the site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package Imports\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk import pos_tag, FreqDist\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.util import ngrams\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /Users/tom/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "The data used for training our models is a publicly-available dataset hosted by Kaggle. Users with a Kaggle account and API token already configued can execute the next cell to download the data directly. \n",
    "\n",
    "Users without a Kaggle account or that just want to access the data can download it from the [source page](https://www.kaggle.com/datasets/kritanjalijain/amazon-reviews?select=amazon_review_polarity_csv.tgz).\n",
    "\n",
    "The dataset is a subset of the Stanford Network Analysis Project (SNAP), which contains approximately 34 million Amazon reviews collected over a 13 year period. Our dataset consists of 1.8 million training samples in each polarity (positive or negative) and 200,000 validation samples in each polarity. The subset was created by labelling reviews that assigned a 1-2 star rating to the negative polarity, and reviews with a 4-5 star rating to the positive polarity. Ratings that gave 3 stars were omitted entirely.\n",
    "\n",
    "Because my goal is to train a classifier that will generalize well across different kinds of products, I chose a dataset that did not specialize in any one category. My hope is that this choice will drive greater accuracy on both Amazon reviews and reviews from other data sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Users with a Kaggle account & API token can run this cell to download the data directly.\n",
    "# import kaggle\n",
    "# kaggle datasets download -d kritanjalijain/amazon-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Stuning even for the non-gamer</td>\n",
       "      <td>This sound track was beautiful! It paints the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The best soundtrack ever to anything.</td>\n",
       "      <td>I'm reading a lot of reviews saying that this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Amazing!</td>\n",
       "      <td>This soundtrack is my favorite music of all ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Excellent Soundtrack</td>\n",
       "      <td>I truly like this soundtrack and I enjoy video...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "      <td>If you've played the game, you know how divine...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                              title  \\\n",
       "0          2                     Stuning even for the non-gamer   \n",
       "1          2              The best soundtrack ever to anything.   \n",
       "2          2                                           Amazing!   \n",
       "3          2                               Excellent Soundtrack   \n",
       "4          2  Remember, Pull Your Jaw Off The Floor After He...   \n",
       "\n",
       "                                                text  \n",
       "0  This sound track was beautiful! It paints the ...  \n",
       "1  I'm reading a lot of reviews saying that this ...  \n",
       "2  This soundtrack is my favorite music of all ti...  \n",
       "3  I truly like this soundtrack and I enjoy video...  \n",
       "4  If you've played the game, you know how divine...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read training data & assign column names\n",
    "df = pd.read_csv('./large_data/train.csv', names=['sentiment', 'title', 'text'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3600000 entries, 0 to 3599999\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Dtype \n",
      "---  ------     ----- \n",
      " 0   sentiment  int64 \n",
      " 1   title      object\n",
      " 2   text       object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 82.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment     0\n",
       "title        77\n",
       "text          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for NaNs - Unimportant because we will not use the title column.\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize sentiment frequency within the dataset\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams.update({'font.size': 13})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "plt.axis([None, None, .9, 1.8])\n",
    "plt.hist(df['sentiment'], color=[86/255,180/255,233/255])\n",
    "ax.set_title('Sentiment Distribution in Dataset')\n",
    "ax.set_ylabel('Number of Occurences (000s)',labelpad=10)\n",
    "ax.set_xlabel('Review Polarity')\n",
    "ax.set_xticklabels(labels = [None, 'Positive', None, None, None, None, 'Negative']);\n",
    "ax.set_yticklabels(labels = [None, '1,000', '1,100', '1,200', '1,300', '1,400', '1,500', '1,600', '1,700', '1,800']);\n",
    "plt.tight_layout()\n",
    "#plt.savefig('../images/sent_dist.png', dpi=500, facecolor='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the data is near-perfectly distributed between the two sentiment classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing is a critical piece of any NLP project.  They appear in order below, and perform the following tasks:\n",
    "\n",
    "**get_wordnet_pos** -- Translates the part of speech tags assigned by nltk into wordnet tags that can be utilized by the lemmatizer.\n",
    "\n",
    "**prepare_text** -- Main cleaner function. Performs the following tasks:\n",
    "- Performs tokenization using a defined regular expression. By default the expression is words of any length that start with a capital or lowercase letter, and end with a lowercase letter.\n",
    "- Converts all text to lowercase.\n",
    "- Removes stopwords.\n",
    "- Performs part of speech tagging and lemmatizes words.\n",
    "- Returns a string of tokens.\n",
    "\n",
    "**ngram_creator** -- Creates a list of tuples containing all possible n-grams in a text, where n is specified at runtime.\n",
    "\n",
    "**visualize_top_n** -- Creates a dictionary of the n most common words in a FrequencyDistribution object, and plots a bar graph of their frequency.\n",
    "\n",
    "**sw_finder** -- Returns a list of common words between two FrequencyDistribution Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "Given the large size of the dataset, I created several helper functions to facilitate efficient text cleaning outside of the model pipelines prepared in the [modeling notebook](modeling_nb.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS-Tag Translator\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    '''\n",
    "    Translate nltk part of speech tags to wordnet tags that can be used by the lemmatizer.\n",
    "    '''\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Cleaner Function\n",
    "\n",
    "def prepare_text(text, sw=stopwords.words('english'), regex_pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"):\n",
    "    \"\"\"\n",
    "    Tokenize, standardize case, remove punctuation, perform part of speech tagging\n",
    "    and lemmatize text from string.\n",
    "    \n",
    "    By default, tokenization is performed using a regular expression that grabs words \n",
    "    that begin with a capital or lowercase letter and end with a lowercase letter.\n",
    "    \"\"\"\n",
    "    # Identify hyperlinks in the subject data & strip them out\n",
    "    # Credit to Prajwal @ https://gitlab.com/praj88/twitter-analytics/blob/master/scripts/twitter-analytics.ipynb\n",
    "    isURL = re.compile(r'http[s]?:// (?:[a-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', re.VERBOSE | re.IGNORECASE)\n",
    "    text = isURL.sub(\"\", text)\n",
    "    \n",
    "    # Tokenize words based on the regular expression stored in regex_pattern\n",
    "    tokenizer = RegexpTokenizer(regex_pattern)\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    \n",
    "    # Convert tokens to lowercase and remove words in the stop_list variable\n",
    "    tokens = [token.lower() for token in tokens if token.lower() not in sw]\n",
    "    \n",
    "    # Perform part of speech tagging\n",
    "    tokens_tagged = pos_tag(tokens)\n",
    "    tokens_tagged = [(word[0], get_wordnet_pos(word[1])) for word in tokens_tagged]\n",
    "    \n",
    "    # Perform lemmatization \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word[0], word[1]) for word in tokens_tagged]\n",
    "    \n",
    "    # Return a string consisting of all tokens\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert prepared text into n-grams.\n",
    "\n",
    "def ngram_creator(text, n):\n",
    "    \"\"\"\n",
    "    Return a list of all possible n-grams from the specified text.\n",
    "    \"\"\"\n",
    "    return list(ngrams(text.split(), n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization Function to plot the n most common words in a frequency distribution object\n",
    "\n",
    "def visualize_top_n(freq_dist, title, n=10):\n",
    "    \"\"\"\n",
    "    Create a dictionary of the n most common words in a frequency distribution and plot a bar\n",
    "    graph illustrating how many times those words appear in the frequency distribution object.\n",
    "    \"\"\"\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    plt.rcParams.update({'font.size': 13})\n",
    "        \n",
    "    # Extract data for plotting\n",
    "    top_n = list(zip(*freq_dist.most_common(n)))\n",
    "    tokens = top_n[0]\n",
    "    counts = top_n[1]\n",
    "\n",
    "    # Set up plot and plot data\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    ax.bar(tokens, counts)\n",
    "\n",
    "    # Customize plot appearance\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.tick_params(axis=\"x\", rotation=90)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save png of image to images folder using title as filename\n",
    "    plt.savefig(f'../images/{title}', dpi=500, facecolor='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to identify common words in positive, negative reviews.\n",
    "\n",
    "def sw_finder(fd1, fd2, n=10):\n",
    "    \"\"\"\n",
    "    Intake two frequency distribution objects and return a list of n words\n",
    "    that appear in both objects.\n",
    "    \"\"\"\n",
    "    return list(dict(fd1.most_common(n)).keys() & dict(fd2.most_common(n)).keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "I began the cleaning process by testing the cleaner function on a single cell. It appears to be working correctly, so I moved on to create a new column called 'text_cleaned' to hold the results of the cleaning function. I then called the ngram_creator function on that cleaned text to create new columns that store bi-grams and tri-grams for each review. Finally, I checked for any instances of failure by the cleaning function to determine whether additional steps were needed. As it turned out, the cleaning function performed well and there were no instances of missing cleaned reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sound track beautiful paint senery mind well would recomend even people hate vid game music play game chrono cross game ever play best music back away crude keyboarding take fresh step grate guitar soulful orchestra would impress anyone care listen\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test cleaner function on one row\n",
    "sample_row = prepare_text(df['text'][0])\n",
    "print(sample_row)\n",
    "\n",
    "# Print original text for inspection\n",
    "df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Apply helper function to 'text' column and store the output in a new column\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_cleaned\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprepare_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Create & store bi-grams in a new column\u001b[39;00m\n\u001b[1;32m      5\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbigrams\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_cleaned\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(ngram_creator, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/spark-cap-env/lib/python3.8/site-packages/pandas/core/series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4324\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4328\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4329\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4330\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4331\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4332\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4431\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/spark-cap-env/lib/python3.8/site-packages/pandas/core/apply.py:1088\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1084\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1085\u001b[0m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m-> 1088\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/spark-cap-env/lib/python3.8/site-packages/pandas/core/apply.py:1143\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1137\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m         \u001b[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m         \u001b[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[1;32m   1142\u001b[0m         \u001b[38;5;66;03m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[0;32m-> 1143\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1146\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/spark-cap-env/lib/python3.8/site-packages/pandas/_libs/lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mprepare_text\u001b[0;34m(text, sw, regex_pattern)\u001b[0m\n\u001b[1;32m     21\u001b[0m tokens \u001b[38;5;241m=\u001b[39m [token\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m tokens \u001b[38;5;28;01mif\u001b[39;00m token\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m sw]\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Perform part of speech tagging\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m tokens_tagged \u001b[38;5;241m=\u001b[39m \u001b[43mpos_tag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m tokens_tagged \u001b[38;5;241m=\u001b[39m [(word[\u001b[38;5;241m0\u001b[39m], get_wordnet_pos(word[\u001b[38;5;241m1\u001b[39m])) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m tokens_tagged]\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Perform lemmatization \u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/spark-cap-env/lib/python3.8/site-packages/nltk/tag/__init__.py:166\u001b[0m, in \u001b[0;36mpos_tag\u001b[0;34m(tokens, tagset, lang)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03mUse NLTK's currently recommended part of speech tagger to\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;124;03mtag the given list of tokens.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m:rtype: list(tuple(str, str))\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    165\u001b[0m tagger \u001b[38;5;241m=\u001b[39m _get_tagger(lang)\n\u001b[0;32m--> 166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_pos_tag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtagset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtagger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/spark-cap-env/lib/python3.8/site-packages/nltk/tag/__init__.py:123\u001b[0m, in \u001b[0;36m_pos_tag\u001b[0;34m(tokens, tagset, tagger, lang)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokens: expected a list of strings, got a string\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 123\u001b[0m     tagged_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mtagger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tagset:  \u001b[38;5;66;03m# Maps to the specified tagset.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m lang \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meng\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/spark-cap-env/lib/python3.8/site-packages/nltk/tag/perceptron.py:187\u001b[0m, in \u001b[0;36mPerceptronTagger.tag\u001b[0;34m(self, tokens, return_conf, use_tagdict)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tag:\n\u001b[1;32m    186\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_features(i, word, context, prev, prev2)\n\u001b[0;32m--> 187\u001b[0m     tag, conf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_conf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m output\u001b[38;5;241m.\u001b[39mappend((word, tag, conf) \u001b[38;5;28;01mif\u001b[39;00m return_conf \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (word, tag))\n\u001b[1;32m    190\u001b[0m prev2 \u001b[38;5;241m=\u001b[39m prev\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/spark-cap-env/lib/python3.8/site-packages/nltk/tag/perceptron.py:66\u001b[0m, in \u001b[0;36mAveragedPerceptron.predict\u001b[0;34m(self, features, return_conf)\u001b[0m\n\u001b[1;32m     64\u001b[0m     weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights[feat]\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m label, weight \u001b[38;5;129;01min\u001b[39;00m weights\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 66\u001b[0m         scores[label] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m value \u001b[38;5;241m*\u001b[39m weight\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Do a secondary alphabetic sort, for stability\u001b[39;00m\n\u001b[1;32m     69\u001b[0m best_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m label: (scores[label], label))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Apply helper function to 'text' column and store the output in a new column\n",
    "df['text_cleaned'] = df['text'].apply(prepare_text)\n",
    "\n",
    "# Create & store bi-grams in a new column\n",
    "df['bigrams'] = df['text_cleaned'].apply(ngram_creator, n=2)\n",
    "\n",
    "# Create & store trigrams in a new column\n",
    "df['trigrams'] = df['text_cleaned'].apply(ngram_creator, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for reviews where the cleaning function failed & display them\n",
    "print(df.isna().sum())\n",
    "df[df['text_cleaned'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframe with cleaned text, sentiment and n-grams, save to csv.\n",
    "df.to_csv('large_data/train_cleaned.csv', columns=['sentiment', 'text', 'text_cleaned', 'bigrams', 'trigrams'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first five rows for visual inspection\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Ten most common words appearing in positive reviews\n",
    "pos_freq_dist = FreqDist(df['text_cleaned'].str.split().explode().loc[df['sentiment'] == 2])\n",
    "visualize_top_n(pos_freq_dist, 'Most Common Words in Positive Reviews', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ten most common words appearing in negative reviews\n",
    "neg_freq_dist = FreqDist(df['text_cleaned'].str.split().explode().loc[df['sentiment'] == 1])\n",
    "visualize_top_n(neg_freq_dist, 'Most Common Words in Negative Reviews', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify and Remove Custom Stopwords\n",
    "The following section will be focused on identifying the most common words in reviews of each sentiment, and finding where these lists intersect. Words that appear frequently in both sentiments begin to lose their meaning, and we will attempt to address this by removing any words that are among the 10 most common in both sentiments. I chose 10 words as the cutoff because there seems to be a breakpoint at 10 words where the same words do not appear in both lists and are not ordered the same in terms of commonality. I created a custom stopwords list using the sw_finder function and extended the default stopwords list to include these common words. I then re-ran the cleaning function and saved the results to a .csv for use in the modeling notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify common words among the 10 most frequent words in reviews of each sentiment\n",
    "train_sw = sw_finder(neg_freq_dist, pos_freq_dist, 10)\n",
    "train_sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend stop_list to include the elements of custom_sw\n",
    "train_sw.extend(stopwords.words('english'))\n",
    "train_sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply helper function to 'text' column and store the output in a new column\n",
    "df['text_cleaned'] = df['text'].apply(prepare_text, sw=train_sw)\n",
    "\n",
    "# Create & store bi-grams in a new column\n",
    "df['bigrams'] = df['text_cleaned'].apply(ngram_creator, n=2)\n",
    "\n",
    "# Create & store trigrams in a new column\n",
    "df['trigrams'] = df['text_cleaned'].apply(ngram_creator, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify reviews where the cleaning function failed & display them\n",
    "print(df.isna().sum())\n",
    "df[df['text_cleaned'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframe with cleaned text and sentiment, save to csv.\n",
    "df.to_csv('./large_data/train_cleaned_10sw.csv', columns=['sentiment', 'text', 'text_cleaned', 'bigrams', 'trigrams'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Test Data\n",
    "For the test data, I followed the same cleaning process and utilized the same functions as on the train data. Although the specific stop words might vary, I followed the same procedure with custom words and removed any words that appeared in the 10 most common words in each sentiment. I saved off .csv files with and without the use of custom stopword filtering to see which will perform better in the [modeling notebook](modeling_nb.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in valdiation data\n",
    "df_test = pd.read_csv('./large_data/test.csv', names=['sentiment', 'title', 'text']) \n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaNs - Unimportant because we will not use the title column.\n",
    "df_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cleaning function to the validation set\n",
    "df_test['text_cleaned'] = df_test['text'].apply(prepare_text)\n",
    "\n",
    "# Create & store trigrams in a new column\n",
    "df_test['bigrams'] = df_test['text_cleaned'].apply(ngram_creator, n=2)\n",
    "\n",
    "# Create & store trigrams in a new column\n",
    "df_test['trigrams'] = df_test['text_cleaned'].apply(ngram_creator, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify reviews where the cleaning function failed & display them\n",
    "print(df_test.isna().sum())\n",
    "df_test[df_test['text_cleaned'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save validation data to a new CSV file\n",
    "df_test.to_csv('./large_data/test_cleaned.csv', columns=['sentiment', 'text', 'text_cleaned', 'bigrams', 'trigrams'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ten most common words appearing in positive test reviews\n",
    "pos_test_dist = FreqDist(df_test['text_cleaned'].str.split().explode().loc[df_test['sentiment'] == 2])\n",
    "visualize_top_n(pos_test_dist, 'Most Common Words in Positive Test Reviews', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ten most common words appearing in negative reviews\n",
    "neg_test_dist = FreqDist(df_test['text_cleaned'].str.split().explode().loc[df_test['sentiment'] == 1])\n",
    "visualize_top_n(neg_test_dist, 'Most Common Words in Negative Test Reviews', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify common words among the 10 most frequent words in reviews of each sentiment\n",
    "test_sw = sw_finder(neg_test_dist, pos_test_dist, 10)\n",
    "test_sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend test_sw to include custom stop words from test data.\n",
    "test_sw.extend(stopwords.words(\"english\")) \n",
    "test_sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-apply cleaning function to 'text' column using identified stopwords \n",
    "df_test['text_cleaned'] = df_test['text'].apply(prepare_text, sw=test_sw)\n",
    "\n",
    "# Create & store bi-grams in a new column\n",
    "df_test['bigrams'] = df_test['text_cleaned'].apply(ngram_creator, n=2)\n",
    "\n",
    "# Create & store trigrams in a new column\n",
    "df_test['trigrams'] = df_test['text_cleaned'].apply(ngram_creator, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify reviews where the cleaning function failed & display them\n",
    "print(df_test.isna().sum())\n",
    "df_test[df_test['text_cleaned'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframe with cleaned text inclusive of custom sw and sentiment, save to csv.\n",
    "df_test.to_csv('./large_data/test_cleaned_10sw.csv', columns=['sentiment', 'text', 'text_cleaned', 'bigrams', 'trigrams'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reddit Product Reveiws\n",
    "As part of the project, I wanted to see how my cleaning process and final model would perform on real-world data. This section covers how I extracted 100 posts from Reddit's r/productreviews subreddit and cleaned the resulting extract for use in our model.\n",
    "\n",
    "Reddit's API requires users to create an account and register their application in order to obtain an oauth token. This process is fairly simple, and can be completed in a matter of minutes [at this link](https://www.reddit.com/prefs/apps). James Briggs has an excellent tutorial available on [Medium](https://towardsdatascience.com/how-to-use-the-reddit-api-in-python-5e05ddfd1e5c), which I followed to get access to the API. **NOTE:** James's example code involves hard coding the API credentials, which is an insecure practice for a notebook that will be stored in a public repository. If you have any intention of storing this notebook in a public repository, please use safe coding practices to protect your API credentials from misuse. Scott Harden has published a [simple blog post](https://swharden.com/blog/2021-05-15-python-credentials/) which outlines several options and their advantages and drawbacks. \n",
    "\n",
    "This notebook is set up to read the necessary API credentials from a text file stored in ./creds/reddit.txt. The creds folder is omitted from my repository for security reasons, so the following bits of code may not function without some additional work. To replicate this process, simply create a creds directory containing a blank reddit.txt file, and paste your application's personal use token, secret token, username and password on the first four lines of reddit.txt. Alternatively, you can create your own credentials file in a location of your choosing and modify the file path in the following cell to point to where it is stored.\n",
    "\n",
    "Not to worry--the cleaned Reddit data will be uploaded to the [data](./data) folder so that the modeling process can be replicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read necessary API credentials from reddit.txt file.\n",
    "\n",
    "with open(\"./creds/reddit.txt\") as f:\n",
    "    lines = f.readlines()\n",
    "    client_id = lines[0].strip()\n",
    "    secret_token = lines[1].strip()\n",
    "    username = lines[2].strip()\n",
    "    password = lines[3].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credit to James Briggs for the starter code used to create our API session.\n",
    "# https://towardsdatascience.com/how-to-use-the-reddit-api-in-python-5e05ddfd1e5c)\n",
    "\n",
    "# Define auth type, inclusive of my Reddit script's API tokens\n",
    "auth = requests.auth.HTTPBasicAuth(client_id, secret_token)\n",
    "\n",
    "# Define my reddit account's username and password to be used in token generation\n",
    "data = {'grant_type': 'password',\n",
    "        'username': username,\n",
    "        'password': password}\n",
    "\n",
    "# Define my application's header information which gives Reddit a brief description of the app\n",
    "headers = {'User-Agent': 'review-finder/0.0.1'}\n",
    "\n",
    "# Send request for an OAuth token\n",
    "res = requests.post('https://www.reddit.com/api/v1/access_token', \n",
    "                    auth = auth, data = data, headers = headers)\n",
    "\n",
    "# Convert response to JSON and extract the access_token value\n",
    "TOKEN = res.json()['access_token']\n",
    "\n",
    "# Add authorization to our headers directory\n",
    "headers = {**headers, **{'Authorization': f\"bearer {TOKEN}\"}}\n",
    "\n",
    "# While the OAuth token is valid (~2 hours), we can add headers=headers to API calls\n",
    "requests.get('https://oauth.reddit.com/api/v1/me', headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to make our first call to extract post data. By default, reddit's API returns 25 posts with each call unless the limit parameter is increased. We will increase this to 100 posts, and execute our first call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an API call using a limit parameter of 100\n",
    "req_new = requests.get(\"https://oauth.reddit.com/r/ProductReviews/new\",\n",
    "                   headers=headers,\n",
    "                   params={'limit': '100'})     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a new dataframe to hold the results of our calls\n",
    "df_red_new = pd.DataFrame()\n",
    "\n",
    "# Loop over the posts in the response\n",
    "for post in req_new.json()['data']['children']:\n",
    "    \n",
    "    # Append relevant post data to dataframe\n",
    "    df_red_new = df_red_new.append({\n",
    "        'subreddit': post['data']['subreddit'],\n",
    "        'title': post['data']['title'],\n",
    "        'selftext': post['data']['selftext']\n",
    "        }, \n",
    "        ignore_index=True)  \n",
    "\n",
    "# Visually inspect the dataframe\n",
    "df_red_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Reviews to .csv prior to cleaning.\n",
    "df_red_new.to_csv('./data/reddit_new.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we visually inspected the dataframe above, we noted that many of the selftext fields were blank. This can happen if a user populates the \"link\" field in a reddit post and does not add any text to their post. For our purposes, we will drop these posts since we don't have an easy way to get the review text from the linked pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert posts with no text to show NaN so they can be dropped.\n",
    "df_red_new.replace(r'^\\s*$', np.NaN, regex=True, inplace=True)\n",
    "df_red_new.dropna(inplace=True)\n",
    "df_red_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we will apply the same text-cleaning and n-gram creation functions to the Reddit text that we used for our Amazon data. We'll also re-check the data for posts with blank \"text_cleaned\" fields. In our case, this appears to happen when users paste a link to their video or text review and no other text in the text box. Reddit renders the video so it can be easily accessed by anyone that visits the subreddit, but we are left without any usable review text to parse. Our cleaning process will vary slightly from the Amazon data for reddit posts--because we do not have a large amount of labeled data, we cannot create custom stopwords for reddit posts. Instead we will use the default English stop words specified by nltk.\n",
    "\n",
    "After the cleaning functions are applied, we are left with 14 of our original 99 posts to pass to our model. This isn't a huge population, but should provide some anecdotal examples of whether or not the model is correctly classifying reviews based on our inspection of the text. That process is covered in the [modeling notebook](./modeling_nb.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cleaning function to the reddit data\n",
    "df_red_new['text_cleaned'] = df_red_new['selftext'].apply(prepare_text)\n",
    "\n",
    "# Create & store trigrams in a new column\n",
    "df_red_new['bigrams'] = df_red_new['text_cleaned'].apply(ngram_creator, n=2)\n",
    "\n",
    "# Create & store trigrams in a new column\n",
    "df_red_new['trigrams'] = df_red_new['text_cleaned'].apply(ngram_creator, n=3)\n",
    "\n",
    "# Convert posts with no text to show NaN so they can be dropped & drop them.\n",
    "df_red_new.replace(r'^\\s*$', np.NaN, regex=True, inplace=True)\n",
    "df_red_new.dropna(inplace=True)\n",
    "\n",
    "# Reset dataframe index after dropping instances of blank posts\n",
    "df_red_new.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Confirm we have no missing values\n",
    "df_red_new.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visually Inspect the Results\n",
    "df_red_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframe with cleaned text inclusive of custom sw and sentiment, save to csv.\n",
    "df_red_new.to_csv('./data/reddit_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Women's Fashion Data\n",
    "As one final test of the model, we will need a labeled set of unseen data. For this purpose, I am utilizing [a dataset from Kaggle](https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews) which contains 23,500 reviews of women's fashion items. Each product is rated on a scale from 1-5, so it should provide a reasonable test of my model's ability to make predictions on a more targeted category of reviews. This data will be used as a validation set in the [modeling notebook](modeling_nb.ipynb) to test the model's accuracy on unseen data.\n",
    "\n",
    "To mimic my training data's preparation, I elected to drop all instances of \"3\" rated products. I considered these neutral for the purposes of the exercise and therefore it is not possible for my model to correctly (or incorrectly) predict them. Like many rating datasets, there is a class imbalance in favor of 5-star rated products, but this should not matter as it will not be used for model training. If anything, it demonstrates a common issue with consumer review data.\n",
    "\n",
    "Finally, I generated a list of custom stopwords and removed them from the dataset to help the model better differentiate between positive and negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the Data, using only the columns needed to evaluate using the final model.\n",
    "df_fash = pd.read_csv('./data/Womens Clothing E-Commerce Reviews.csv', index_col=0, \n",
    "                      usecols = ['Clothing ID', 'Review Text', 'Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sentiment frequency within the dataset\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams.update({'font.size': 13})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "plt.hist(df_fash['Rating'], color=[86/255,180/255,233/255])\n",
    "ax.set_title(\"Sentiment Distribution in Women's Fashion Dataset\")\n",
    "ax.set_ylabel('Number of Occurences')\n",
    "ax.set_xlabel('Review Polarity')\n",
    "plt.tight_layout();\n",
    "#plt.savefig('../images/sent_dist_fashion.png', dpi=500, facecolor='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop reviews with a rating of 3.0\n",
    "df_fash = df_fash[df_fash['Rating'] != 3]\n",
    "df_fash['Rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review info\n",
    "df_fash.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert posts with no text to show NaN so they can be dropped & drop them.\n",
    "df_fash.replace(r'^\\s*$', np.NaN, regex=True, inplace=True)\n",
    "df_fash.dropna(inplace=True)\n",
    "\n",
    "# Reset dataframe index after dropping instances of blank posts\n",
    "df_fash.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Confirm we have no missing values\n",
    "df_fash.isna().sum()\n",
    "\n",
    "# Apply cleaning function to the reddit data\n",
    "df_fash['text_cleaned'] = df_fash['Review Text'].apply(prepare_text)\n",
    "\n",
    "# Create & store trigrams in a new column\n",
    "df_fash['bigrams'] = df_fash['text_cleaned'].apply(ngram_creator, n=2)\n",
    "\n",
    "# Create & store trigrams in a new column\n",
    "df_fash['trigrams'] = df_fash['text_cleaned'].apply(ngram_creator, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm no missing fields\n",
    "df_fash.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visually inspect header\n",
    "df_fash.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin ratings into binary categories for use in final model\n",
    "df_fash.loc[df_fash['Rating'].between(1, 2, 'both'), 'sentiment'] = 1\n",
    "df_fash.loc[df_fash['Rating'].between(4, 5, 'both'), 'sentiment'] = 2\n",
    "df_fash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned fashion data to .csv\n",
    "df_fash.to_csv('./data/fashion_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ten most common words appearing in positive fashion reviews\n",
    "pos_fash_dist = FreqDist(df_fash['text_cleaned'].str.split().explode().loc[df_fash['sentiment'] == 2])\n",
    "visualize_top_n(pos_fash_dist, 'Most Common Words in Positive Fashion Reviews', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ten most common words appearing in positive fashion reviews\n",
    "neg_fash_dist = FreqDist(df_fash['text_cleaned'].str.split().explode().loc[df_fash['sentiment'] == 1])\n",
    "visualize_top_n(neg_fash_dist, 'Most Common Words in Negative Fashion Reviews', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify common words among the 10 most frequent words in reviews of each sentiment\n",
    "fash_sw = sw_finder(neg_fash_dist, pos_fash_dist, 10)\n",
    "fash_sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend test_sw to include custom stop words from test data.\n",
    "fash_sw.extend(stopwords.words(\"english\")) \n",
    "fash_sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cleaning function to the fashion data using custom stopwords\n",
    "df_fash['text_cleaned'] = df_fash['Review Text'].apply(prepare_text, sw=fash_sw)\n",
    "\n",
    "# Create & store trigrams in a new column\n",
    "df_fash['bigrams'] = df_fash['text_cleaned'].apply(ngram_creator, n=2)\n",
    "\n",
    "# Create & store trigrams in a new column\n",
    "df_fash['trigrams'] = df_fash['text_cleaned'].apply(ngram_creator, n=3)\n",
    "\n",
    "# Convert posts with no text to show NaN so they can be dropped & drop them.\n",
    "df_fash.replace(r'^\\s*$', np.NaN, regex=True, inplace=True)\n",
    "df_fash.dropna(inplace=True)\n",
    "\n",
    "# Reset dataframe index after dropping instances of blank posts\n",
    "df_fash.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Confirm we have no missing values\n",
    "df_fash.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned fashion data to .csv\n",
    "df_fash.to_csv('./data/fashion_cleaned_10sw.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spark-cap-env)",
   "language": "python",
   "name": "spark-cap-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
